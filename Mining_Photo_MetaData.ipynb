{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elephant-xyz/photo-meta-data-ai/blob/main/Mining_Photo_MetaData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILCxMc0LIsi-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Photo Mining Process\n",
        "\n"
      ],
      "metadata": {
        "id": "mz5mj3mc9A9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 1: Upload .env"
      ],
      "metadata": {
        "id": "hFmK-TZjbaSG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 2: Upload county-results.csv"
      ],
      "metadata": {
        "id": "llfHfb9Je810",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4A8fm24ILQ8s"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 3: Upload seed-results.csv\n"
      ],
      "metadata": {
        "id": "2ggNUP94fJqh",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 4: Upload your images as a .zip file named with the parcel ID, like 52434205310037080.zip."
      ],
      "metadata": {
        "id": "QJaXm1VQo6lx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ctypes import c_void_p\n",
        "# @title Step 2: Prepare\n",
        "# @title  {\"vertical-output\":true}\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import re\n",
        "import sys\n",
        "import csv\n",
        "import json\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def fetch_schema_cids():\n",
        "    \"\"\"Fetch the seed and county schema CIDs from the schema manifest API\"\"\"\n",
        "    manifest_url = \"https://lexicon.elephant.xyz/json-schemas/schema-manifest.json\"\n",
        "\n",
        "    try:\n",
        "        response = requests.get(manifest_url, timeout=30)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        manifest_data = response.json()\n",
        "\n",
        "        schema_cids = {}\n",
        "\n",
        "        # Extract Seed data group CID\n",
        "        if \"Seed\" in manifest_data:\n",
        "            seed_cid = manifest_data[\"Seed\"][\"ipfsCid\"]\n",
        "            schema_cids[\"seed\"] = seed_cid\n",
        "\n",
        "        # Extract County data group CID\n",
        "        if \"County\" in manifest_data:\n",
        "            county_cid = manifest_data[\"County\"][\"ipfsCid\"]\n",
        "            schema_cids[\"county\"] = county_cid\n",
        "\n",
        "        return schema_cids\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching schema manifest: {e}\")\n",
        "        raise\n",
        "\n",
        "def extract_images(parcel_id):\n",
        "    \"\"\"Extract JPG files from parcel zip, skip macOS files\"\"\"\n",
        "    zip_path = f\"/content/{parcel_id}.zip\"\n",
        "    extract_path = f\"images/{parcel_id}\"\n",
        "    temp_path = f\"/tmp/{parcel_id}_temp\"\n",
        "\n",
        "    if not os.path.exists(zip_path):\n",
        "        return None\n",
        "\n",
        "    os.makedirs(extract_path, exist_ok=True)\n",
        "    os.makedirs(temp_path, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        # Extract only JPG files, exclude macOS files\n",
        "        subprocess.run([\n",
        "            'unzip', '-j', '-o', zip_path, '-d', temp_path,\n",
        "            '*.jpg', '*.jpeg', '*.JPG', '*.JPEG',\n",
        "            '-x', '__MACOSX/*', '*.DS_Store'\n",
        "        ], capture_output=True, text=True)\n",
        "\n",
        "        extracted_count = 0\n",
        "        if os.path.exists(temp_path):\n",
        "            for file in os.listdir(temp_path):\n",
        "                if file.lower().endswith(('.jpg', '.jpeg')):\n",
        "                    source = os.path.join(temp_path, file)\n",
        "                    target = os.path.join(extract_path, file)\n",
        "                    if os.path.exists(source):\n",
        "                        shutil.copy2(source, target)\n",
        "                        extracted_count += 1\n",
        "\n",
        "        if os.path.exists(temp_path):\n",
        "            shutil.rmtree(temp_path)\n",
        "\n",
        "        return extract_path if extracted_count > 0 else None\n",
        "\n",
        "    except Exception:\n",
        "        if os.path.exists(temp_path):\n",
        "            shutil.rmtree(temp_path)\n",
        "        return None\n",
        "\n",
        "\n",
        "def ensure_directory(file_path):\n",
        "    \"\"\"Ensure the directory for the file exists\"\"\"\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if directory and not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "\n",
        "def create_parcel_folder(parcel_id):\n",
        "    # Create folder name based on parcel_id\n",
        "    clean_parcel_id = re.sub(r\"[^\\w\\-_]\", \"_\", str(parcel_id))\n",
        "    folder_name = f\"output/{clean_parcel_id}\"\n",
        "    ensure_directory(folder_name + \"/\")\n",
        "    return folder_name\n",
        "\n",
        "\n",
        "def install_photo_meta_data_ai():\n",
        "    \"\"\"Install photo-meta-data-ai package from GitHub\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run([\n",
        "            sys.executable, '-m', 'pip', 'install',\n",
        "            '--force-reinstall', '--no-cache-dir',\n",
        "            'git+https://github.com/elephant-xyz/photo-meta-data-ai.git'\n",
        "        ], capture_output=True, text=True, timeout=300)\n",
        "\n",
        "        with open('/content/install_log.txt', 'w') as f:\n",
        "            f.write(\"STDOUT:\\n\")\n",
        "            f.write(result.stdout)\n",
        "            f.write(\"\\nSTDERR:\\n\")\n",
        "            f.write(result.stderr)\n",
        "            f.write(f\"\\nReturn code: {result.returncode}\")\n",
        "\n",
        "        return result.returncode == 0\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        return False\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def copy_images_to_output():\n",
        "   \"\"\"Copy images from images/<parcel_id>/ to output/<parcel_id>/\"\"\"\n",
        "   try:\n",
        "       source_dir = \"/content/images\"\n",
        "       output_dir = \"/content/output\"\n",
        "\n",
        "       if os.path.exists(source_dir):\n",
        "           shutil.copytree(source_dir, output_dir, dirs_exist_ok=True)\n",
        "           return True\n",
        "       return False\n",
        "   except:\n",
        "       return False\n",
        "\n",
        "\n",
        "def extract_datacids_from_csv(csv_path):\n",
        "    \"\"\"Extract all dataCIDs from a CSV file.\"\"\"\n",
        "    datacids = []\n",
        "\n",
        "    with open(csv_path, 'r') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            if 'dataCid' in row and row['dataCid']:\n",
        "                datacid = row['dataCid'].strip()\n",
        "                if datacid:\n",
        "                    datacids.append(datacid)\n",
        "\n",
        "    return datacids\n",
        "\n",
        "\n",
        "def traverse_and_download(cids, destination_folder):\n",
        "    \"\"\"\n",
        "    Download CIDs and all related CIDs by traversing relationships.\n",
        "    Creates folder structure: destination_folder/cid/ for each CID in the list.\n",
        "\n",
        "    Args:\n",
        "        cids (list): List of root CIDs to start traversing from\n",
        "        destination_folder (str): The destination folder name\n",
        "    \"\"\"\n",
        "    total_downloaded = 0\n",
        "\n",
        "    for cid in cids:\n",
        "        downloaded = set()\n",
        "\n",
        "        # Create folder structure for this CID\n",
        "        main_folder = Path(f\"{destination_folder}/{cid}\")\n",
        "        main_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        def traverse_cid(current_cid):\n",
        "            \"\"\"Recursively fetch CID and traverse relationships\"\"\"\n",
        "            if current_cid in downloaded:\n",
        "                return\n",
        "\n",
        "\n",
        "\n",
        "            try:\n",
        "                response = requests.get(f\"https://ipfs.io/ipfs/{current_cid}\", timeout=30)\n",
        "                data = response.json()\n",
        "                # Save the JSON file\n",
        "                file_path = main_folder / f\"{current_cid}.json\"\n",
        "                with open(file_path, 'w') as f:\n",
        "                    json.dump(data, f, indent=2)\n",
        "\n",
        "                downloaded.add(current_cid)\n",
        "\n",
        "                # Look for relationships\n",
        "                if \"relationships\" in data:\n",
        "                    for key, value in data[\"relationships\"].items():\n",
        "                        if value is None:\n",
        "                            # Skip null relationships\n",
        "                            continue\n",
        "                        elif isinstance(value, dict) and \"/\" in value:\n",
        "                            # Single CID reference\n",
        "                            related_cid = value[\"/\"]\n",
        "                            traverse_cid(related_cid)\n",
        "                        elif isinstance(value, list):\n",
        "                            # Array of CID references\n",
        "                            for i, item in enumerate(value):\n",
        "                                if isinstance(item, dict) and \"/\" in item:\n",
        "                                    related_cid = item[\"/\"]\n",
        "                                    traverse_cid(related_cid)\n",
        "\n",
        "                # Look for \"from\" and \"to\" fields\n",
        "                for field in [\"from\", \"to\"]:\n",
        "                    if field in data:\n",
        "                        value = data[field]\n",
        "                        if isinstance(value, dict) and \"/\" in value:\n",
        "                            # Single CID reference\n",
        "                            related_cid = value[\"/\"]\n",
        "                            traverse_cid(related_cid)\n",
        "                        elif isinstance(value, list):\n",
        "                            # Array of CID references\n",
        "                            for item in value:\n",
        "                                if isinstance(item, dict) and \"/\" in item:\n",
        "                                    related_cid = item[\"/\"]\n",
        "                                    traverse_cid(related_cid)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading CID {current_cid}: {e}\")\n",
        "\n",
        "        # Start traversal for this root CID\n",
        "        traverse_cid(cid)\n",
        "\n",
        "        total_downloaded += len(downloaded)\n",
        "\n",
        "\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def rename_and_update_references(cids, parent_folder):\n",
        "    \"\"\"\n",
        "    Rename JSON files to meaningful names and update all CID references to relative paths.\n",
        "    Keep the root CID filename unchanged. Can process single CID or list of CIDs.\n",
        "\n",
        "    Args:\n",
        "        cids (str or list): Single CID or list of CIDs to process\n",
        "        parent_folder (str): The parent folder path (e.g., 'seed')\n",
        "    \"\"\"\n",
        "    # Convert single CID to list for uniform processing\n",
        "    if isinstance(cids, str):\n",
        "        cids = [cids]\n",
        "\n",
        "    total_processed = 0\n",
        "\n",
        "    for cid in cids:\n",
        "\n",
        "        # Construct the full folder path\n",
        "        folder = Path(f\"{parent_folder}/{cid}\")\n",
        "\n",
        "        if not folder.exists():\n",
        "            continue\n",
        "\n",
        "        # The root file should match the CID\n",
        "        root_file = folder / f\"{cid}.json\"\n",
        "\n",
        "        if not root_file.exists():\n",
        "            continue\n",
        "\n",
        "        # Track CID to new filename mapping for this folder\n",
        "        cid_to_filename = {}\n",
        "        processed_files = set()\n",
        "\n",
        "        # Track naming counters to handle duplicates\n",
        "        name_counters = {}\n",
        "\n",
        "        # Root CID keeps its original name\n",
        "        cid_to_filename[cid] = f\"{cid}.json\"\n",
        "\n",
        "        def get_meaningful_name(file_cid, relationship_key=None, file_data=None, index=None):\n",
        "          \"\"\"Generate meaningful filename based on content or relationship\"\"\"\n",
        "          base_name = None\n",
        "\n",
        "          # Always prioritize content-based naming for specific types\n",
        "          if file_data:\n",
        "              if \"parcel_identifier\" in file_data:\n",
        "                  base_name = \"property\"\n",
        "              elif \"parcel_id\" in file_data:\n",
        "                  base_name = \"property_seed\"\n",
        "              elif \"full_address\" in file_data:\n",
        "                  base_name = \"address_data\"\n",
        "              elif \"from\" in file_data or \"to\" in file_data:\n",
        "                  base_name = \"connection\"\n",
        "              elif \"label\" in file_data and \"Seed\" in file_data[\"label\"]:\n",
        "                  schema_cids = fetch_schema_cids()\n",
        "                  base_name = schema_cids[\"seed\"]\n",
        "              elif \"label\" in file_data and \"County\" in file_data[\"label\"]:\n",
        "                  schema_cids = fetch_schema_cids()\n",
        "                  base_name = schema_cids[\"seed\"]\n",
        "\n",
        "          # Only use relationship key if no content pattern matched\n",
        "          if not base_name and relationship_key:\n",
        "              if index is not None:\n",
        "                  base_name = f\"{relationship_key}_{index}\"\n",
        "              else:\n",
        "                  base_name = relationship_key\n",
        "\n",
        "          # Final fallback to shortened CID\n",
        "          if not base_name:\n",
        "              base_name = file_cid[:8]\n",
        "\n",
        "          # Handle duplicate names by adding counter\n",
        "          if base_name in name_counters:\n",
        "              name_counters[base_name] += 1\n",
        "              final_name = f\"{base_name}_{name_counters[base_name]}\"\n",
        "          else:\n",
        "              name_counters[base_name] = 0\n",
        "              final_name = base_name\n",
        "          return f\"{final_name}.json\"\n",
        "\n",
        "        def process_file(file_cid, relationship_key=None, index=None):\n",
        "            \"\"\"Process a single file and its references\"\"\"\n",
        "            if file_cid in processed_files:\n",
        "                return cid_to_filename.get(file_cid)\n",
        "\n",
        "            file_path = folder / f\"{file_cid}.json\"\n",
        "            if not file_path.exists():\n",
        "                return None\n",
        "\n",
        "            # Load file content\n",
        "            with open(file_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            # Determine new filename (skip if it's the root CID)\n",
        "            new_filename = get_meaningful_name(file_cid, relationship_key, data, index)\n",
        "            cid_to_filename[file_cid] = new_filename\n",
        "\n",
        "            processed_files.add(file_cid)\n",
        "\n",
        "            # Process relationships in the current file\n",
        "            if \"relationships\" in data:\n",
        "                for key, value in data[\"relationships\"].items():\n",
        "                    if value is None:\n",
        "                        # Skip null relationships\n",
        "                        continue\n",
        "                    elif isinstance(value, dict) and \"/\" in value:\n",
        "                        # Single CID reference\n",
        "                        related_cid = value[\"/\"]\n",
        "                        if not related_cid.startswith(\"./\"):  # Only process actual CIDs, not already converted paths\n",
        "                            process_file(related_cid, key)\n",
        "                    elif isinstance(value, list):\n",
        "                        # Multiple CID references\n",
        "                        for i, item in enumerate(value):\n",
        "                            if isinstance(item, dict) and \"/\" in item:\n",
        "                                related_cid = item[\"/\"]\n",
        "                                if not related_cid.startswith(\"./\"):  # Only process actual CIDs\n",
        "                                    process_file(related_cid, key, i)\n",
        "\n",
        "            # Process \"from\" and \"to\" fields\n",
        "            for field in [\"from\", \"to\"]:\n",
        "                if field in data:\n",
        "                    value = data[field]\n",
        "                    if isinstance(value, dict) and \"/\" in value:\n",
        "                        related_cid = value[\"/\"]\n",
        "                        if not related_cid.startswith(\"./\"):  # Only process actual CIDs\n",
        "                            process_file(related_cid, field)\n",
        "                    elif isinstance(value, list):\n",
        "                        for i, item in enumerate(value):\n",
        "                            if isinstance(item, dict) and \"/\" in item:\n",
        "                                related_cid = item[\"/\"]\n",
        "                                if not related_cid.startswith(\"./\"):  # Only process actual CIDs\n",
        "                                    process_file(related_cid, field, i)\n",
        "\n",
        "            return cid_to_filename.get(file_cid)\n",
        "\n",
        "        # Start processing from root file\n",
        "        process_file(cid)\n",
        "\n",
        "        # Now update all references and rename files\n",
        "        for file_cid, new_filename in cid_to_filename.items():\n",
        "            old_file_path = folder / f\"{file_cid}.json\"\n",
        "            new_file_path = folder / new_filename\n",
        "\n",
        "            if not old_file_path.exists():\n",
        "                continue\n",
        "\n",
        "            # Load and update file content\n",
        "            with open(old_file_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            # Update references in this file\n",
        "            if \"relationships\" in data:\n",
        "                for key, value in data[\"relationships\"].items():\n",
        "                    if isinstance(value, dict) and \"/\" in value:\n",
        "                        # Single CID reference\n",
        "                        referenced_cid = value[\"/\"]\n",
        "                        if referenced_cid in cid_to_filename and not referenced_cid.startswith(\"./\"):\n",
        "                            data[\"relationships\"][key] = {\"/\": f\"./{cid_to_filename[referenced_cid]}\"}\n",
        "                    elif isinstance(value, list):\n",
        "                        # Multiple CID references\n",
        "                        updated_list = []\n",
        "                        for item in value:\n",
        "                            if isinstance(item, dict) and \"/\" in item:\n",
        "                                referenced_cid = item[\"/\"]\n",
        "                                if referenced_cid in cid_to_filename and not referenced_cid.startswith(\"./\"):\n",
        "                                    updated_list.append({\"/\": f\"./{cid_to_filename[referenced_cid]}\"})\n",
        "                                else:\n",
        "                                    updated_list.append(item)\n",
        "                            else:\n",
        "                                updated_list.append(item)\n",
        "                        data[\"relationships\"][key] = updated_list\n",
        "\n",
        "            # Update \"from\" and \"to\" fields\n",
        "            for field in [\"from\", \"to\"]:\n",
        "                if field in data:\n",
        "                    value = data[field]\n",
        "                    if isinstance(value, dict) and \"/\" in value:\n",
        "                        referenced_cid = value[\"/\"]\n",
        "                        if referenced_cid in cid_to_filename and not referenced_cid.startswith(\"./\"):\n",
        "                            data[field] = {\"/\": f\"./{cid_to_filename[referenced_cid]}\"}\n",
        "                    elif isinstance(value, list):\n",
        "                        updated_list = []\n",
        "                        for item in value:\n",
        "                            if isinstance(item, dict) and \"/\" in item:\n",
        "                                referenced_cid = item[\"/\"]\n",
        "                                if referenced_cid in cid_to_filename and not referenced_cid.startswith(\"./\"):\n",
        "                                    updated_list.append({\"/\": f\"./{cid_to_filename[referenced_cid]}\"})\n",
        "                                else:\n",
        "                                    updated_list.append(item)\n",
        "                            else:\n",
        "                                updated_list.append(item)\n",
        "                        data[field] = updated_list\n",
        "\n",
        "            # Save updated content to new file\n",
        "            with open(new_file_path, 'w') as f:\n",
        "                json.dump(data, f, indent=2)\n",
        "\n",
        "            # Remove old file if name changed\n",
        "            if old_file_path != new_file_path:\n",
        "                old_file_path.unlink()\n",
        "\n",
        "        total_processed += len(processed_files)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    parcel_id = \"52434205310037080\" # @param {\"type\":\"string\"}\n",
        "\n",
        "    extract_images(parcel_id)\n",
        "    create_parcel_folder(parcel_id)\n",
        "    install_photo_meta_data_ai()\n",
        "    copy_images_to_output()\n",
        "    datacid = extract_datacids_from_csv(\"seed-results.csv\")\n",
        "    countydatacid = extract_datacids_from_csv(\"county-results.csv\")\n",
        "    traverse_and_download(datacid, \"seed\")\n",
        "    traverse_and_download(countydatacid, \"county\")\n",
        "    rename_and_update_references(datacid, \"seed\")\n",
        "    rename_and_update_references(countydatacid, \"county\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "id": "pA9w0knZbyRQ",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 5: Transform\n",
        "! pip3 install python-dotenv -q\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import csv\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "\n",
        "def get_photo_cid_and_html_link(path=\"photo-results.csv\"):\n",
        "    \"\"\"Get photo CID and HTML link from upload results CSV\"\"\"\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        first_row = next(reader, None)\n",
        "        if first_row is None:\n",
        "            raise ValueError(\"CSV file is empty\")\n",
        "        return first_row[\"dataGroupCid\"], first_row[\"htmlLink\"]\n",
        "\n",
        "\n",
        "def has_submit_errors(path=\"submit_errors.csv\"):\n",
        "    \"\"\"\n",
        "    Returns True if submit_errors.csv has at least one row (after header).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "            reader = csv.DictReader(csvfile)\n",
        "            return next(reader, None) is not None\n",
        "    except FileNotFoundError:\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "def process_photo_data(input_dir=\"output\", property_filename=\"my_property.json\"):\n",
        "    \"\"\"Step 1: Process photo data\"\"\"\n",
        "    os.chdir(\"/content\")\n",
        "\n",
        "    try:\n",
        "        cmd = f\"process-photo-data --input-dir {input_dir} --property-filename {property_filename}\"\n",
        "        subprocess.run(cmd, shell=True, check=True)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "def copy_group_to_output(output_folder=\"output\", seed_folder=\"seed\", rename_to_cid=True):\n",
        "\n",
        "    if not os.path.exists(output_folder) or not os.path.exists(seed_folder):\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        # Get all parcel ID folders in output\n",
        "        output_parcel_folders = [f for f in os.listdir(output_folder)\n",
        "                               if os.path.isdir(os.path.join(output_folder, f))]\n",
        "\n",
        "        # Get all CID folders in seed\n",
        "        seed_cid_folders = [f for f in os.listdir(seed_folder)\n",
        "                          if os.path.isdir(os.path.join(seed_folder, f))]\n",
        "\n",
        "        # Create mapping by reading JSON files in seed folders\n",
        "        parcel_to_cid_mapping = {}\n",
        "\n",
        "        for cid in seed_cid_folders:\n",
        "            cid_folder_path = os.path.join(seed_folder, cid)\n",
        "\n",
        "            # Look for JSON files in the CID folder\n",
        "            for file in os.listdir(cid_folder_path):\n",
        "                if file.endswith('.json'):\n",
        "                    json_file_path = os.path.join(cid_folder_path, file)\n",
        "                    try:\n",
        "                        with open(json_file_path, 'r') as f:\n",
        "                            data = json.load(f)\n",
        "\n",
        "                        # Look for parcel_id or parcel_identifier in the JSON data\n",
        "                        parcel_id = None\n",
        "                        if 'parcel_id' in data:\n",
        "                            parcel_id = str(data['parcel_id']).strip()\n",
        "                        elif 'parcel_identifier' in data:\n",
        "                            parcel_id = str(data['parcel_identifier']).strip()\n",
        "\n",
        "                        if parcel_id:\n",
        "                            # Normalize parcel ID by removing dashes\n",
        "                            normalized_parcel_id = parcel_id.replace('-', '')\n",
        "                            if normalized_parcel_id:\n",
        "                                parcel_to_cid_mapping[normalized_parcel_id] = cid\n",
        "                                break\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "        # Process each parcel folder\n",
        "        for parcel_id in output_parcel_folders:\n",
        "            # Normalize the parcel folder name (remove dashes) to match our mapping\n",
        "            normalized_parcel_id = parcel_id.replace('-', '')\n",
        "\n",
        "            # Find corresponding CID\n",
        "            corresponding_cid = parcel_to_cid_mapping.get(normalized_parcel_id)\n",
        "\n",
        "            if corresponding_cid and corresponding_cid in seed_cid_folders:\n",
        "                # Paths\n",
        "                output_parcel_path = os.path.join(output_folder, parcel_id)\n",
        "                seed_cid_path = os.path.join(seed_folder, corresponding_cid)\n",
        "\n",
        "                # Copy all content from seed CID folder to output parcel folder\n",
        "                for item in os.listdir(seed_cid_path):\n",
        "                    source_path = os.path.join(seed_cid_path, item)\n",
        "                    dest_path = os.path.join(output_parcel_path, item)\n",
        "\n",
        "                    if os.path.isfile(source_path):\n",
        "                        shutil.copy2(source_path, dest_path)\n",
        "                    elif os.path.isdir(source_path):\n",
        "                        if os.path.exists(dest_path):\n",
        "                            shutil.rmtree(dest_path)\n",
        "                        shutil.copytree(source_path, dest_path)\n",
        "\n",
        "                # Rename parcel ID folder to CID if requested\n",
        "                if rename_to_cid:\n",
        "                    new_output_cid_path = os.path.join(output_folder, corresponding_cid)\n",
        "\n",
        "                    if not os.path.exists(new_output_cid_path):\n",
        "                        os.rename(output_parcel_path, new_output_cid_path)\n",
        "                    else:\n",
        "                        # If CID folder already exists, merge content and remove parcel folder\n",
        "                        for item in os.listdir(output_parcel_path):\n",
        "                            source_path = os.path.join(output_parcel_path, item)\n",
        "                            dest_path = os.path.join(new_output_cid_path, item)\n",
        "\n",
        "                            if os.path.isfile(source_path):\n",
        "                                shutil.copy2(source_path, dest_path)\n",
        "                            elif os.path.isdir(source_path):\n",
        "                                if os.path.exists(dest_path):\n",
        "                                    shutil.rmtree(dest_path)\n",
        "                                shutil.copytree(source_path, dest_path)\n",
        "\n",
        "                        shutil.rmtree(output_parcel_path)\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def run_validate_and_upload():\n",
        "    \"\"\"Run validation and upload process\"\"\"\n",
        "    try:\n",
        "\n",
        "        subprocess.run(\n",
        "            [\"npx\", \"-y\", \"@elephant-xyz/cli\", \"validate-and-upload\", \"output\", \"--output-csv\", \"photo-results.csv\"],\n",
        "            stdout=subprocess.DEVNULL,    # hide stdout\n",
        "            stderr=subprocess.PIPE,       # capture stderr\n",
        "            check=True,\n",
        "            text=True                     # stderr as string\n",
        "        )\n",
        "\n",
        "        # If there are recorded errors - stop execution\n",
        "\n",
        "\n",
        "        # Otherwise - read results\n",
        "        photo_group_cid, html_link = get_photo_cid_and_html_link()\n",
        "        print(\"✅ Transform done\\n\")\n",
        "        print(f\"Photo group CID: {photo_group_cid}\\n\")\n",
        "        print(f\"HTML link: {html_link}\")\n",
        "        return True\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # handle command execution errors\n",
        "        print(f\"Command failed (exit code {e.returncode}):\", file=sys.stderr)\n",
        "        if e.stderr:\n",
        "            print(e.stderr.strip(), file=sys.stderr)\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Validation and upload failed: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main processing pipeline\"\"\"\n",
        "    #os.chdir(\"/content\")\n",
        "    process_photo_data(\"output\",\"property_seed.json\")\n",
        "    copy_group_to_output(\"output\",\"county\",False)\n",
        "    copy_group_to_output(\"output\",\"seed\")\n",
        "    run_validate_and_upload()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZVVc5czMqhXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc175de-7b95-482b-a51e-8de1ce958f68",
        "cellView": "form"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Transform done\n",
            "\n",
            "Photo group CID: bafkreicmbnr6u6onlqyrhewewzzbil54rpveyknbvlwudx56zclyapmsp4\n",
            "\n",
            "HTML link: http://dweb.link/ipfs/bafybeicmgbjxqidphyedaxjesztjauzqzphpviaklbbwi5yuolby6cddgq\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 6: Validate\n",
        "! pip3 install python-dotenv -q\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "\n",
        "def get_photo_cid_and_html_link(path=\"/content/photo-results.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        first_row = next(reader, None)\n",
        "        if first_row is None:\n",
        "            raise ValueError(\"CSV file is empty\")\n",
        "        return first_row[\"dataGroupCid\"], first_row[\"htmlLink\"]\n",
        "\n",
        "\n",
        "def has_submit_errors(path=\"/content/submit_errors.csv\"):\n",
        "    \"\"\"\n",
        "    Повертає True, якщо у файлі submit_errors.csv є хоча б один рядок (після заголовку).\n",
        "    \"\"\"\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        return next(reader, None) is not None\n",
        "\n",
        "\n",
        "def run_validate_and_upload():\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"npx\", \"-y\", \"@elephant-xyz/cli\", \"validate-and-upload\", \"output\", \"--output-csv\", \"photo-results.csv\"],\n",
        "            stdout=subprocess.DEVNULL,    # ховаємо stdout\n",
        "            stderr=subprocess.PIPE,       # ловимо stderr у буфер\n",
        "            check=True,\n",
        "            text=True                     # stderr як рядок\n",
        "        )\n",
        "\n",
        "\n",
        "        # Інакше — читаємо результати\n",
        "        seed_group_cid, html_link = get_photo_cid_and_html_link()\n",
        "        print(\"✅ Validate done\\n\")\n",
        "        print(f\"Photo group CID: {seed_group_cid}\\n\")\n",
        "        print(f\"HTML link: {html_link}\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # обробка помилок виконання команди\n",
        "        print(f\"Command failed (exit code {e.returncode}):\", file=sys.stderr)\n",
        "        print(e.stderr.strip(), file=sys.stderr)\n",
        "        sys.exit(e.returncode)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_validate_and_upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "QzS4tbDn9BUM",
        "outputId": "eff08611-f03c-4511-f1e1-e123a2729173"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Validate done\n",
            "\n",
            "Photo group CID: bafkreicmbnr6u6onlqyrhewewzzbil54rpveyknbvlwudx56zclyapmsp4\n",
            "\n",
            "HTML link: http://dweb.link/ipfs/bafybeiafdnhn3am7tdaufpyvonn5d5alcfkgdjgpggt3ts2eyjnhghrlom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 4: Upload\n",
        "! pip3 install python-dotenv requests -q\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "import requests\n",
        "\n",
        "\n",
        "def get_photo_info(path=\"photo-results.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        first_row = next(reader, None)\n",
        "        if first_row is None:\n",
        "            raise ValueError(\"CSV file is empty\")\n",
        "\n",
        "        second_row = next(reader, None)\n",
        "        if second_row is None:\n",
        "            raise ValueError(\"CSV file has only one row\")\n",
        "        return second_row\n",
        "\n",
        "\n",
        "def has_submit_errors(path=\"submit_errors.csv\"):\n",
        "    \"\"\"\n",
        "    Повертає True, якщо у файлі submit_errors.csv є хоча б один рядок (після заголовку).\n",
        "    \"\"\"\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        return next(reader, None) is not None\n",
        "\n",
        "\n",
        "def count_upload_records(path=\"photo-results.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        return sum(1 for _ in reader)\n",
        "\n",
        "\n",
        "def collect_data_ipfs_links(data_cid):\n",
        "    print(data_cid)\n",
        "    # Handle data_cid as either a single CID or a list of CIDs\n",
        "    if isinstance(data_cid, list):\n",
        "        photo_data_links = [f\"https://ipfs.io/ipfs/{cid}\" for cid in data_cid]\n",
        "        # Use the first CID to get the structure data\n",
        "        photo_data = requests.get(photo_data_links[0]).json()\n",
        "    else:\n",
        "        photo_data_links = f\"https://ipfs.io/ipfs/{data_cid}\"\n",
        "        photo_data = requests.get(photo_data_links).json()\n",
        "\n",
        "    # Extract property seed CID from the correct relationship\n",
        "    property_photo_cid = photo_data[\"relationships\"][\"property_seed_has_file\"][0][\"/\"]  # Access first item in list\n",
        "    property_photo_link = f\"https://ipfs.io/ipfs/{property_photo_cid}\"  # Fixed variable name\n",
        "\n",
        "    # Get property seed data\n",
        "    property_seed_data = requests.get(property_photo_link).json()  # Fixed variable name\n",
        "\n",
        "    # Extract property and address CIDs\n",
        "    property_cid, address_cid = property_seed_data[\"from\"][\"/\"], property_seed_data[\"to\"][\"/\"]\n",
        "\n",
        "    # Create links\n",
        "    property_link = f\"https://ipfs.io/ipfs/{property_cid}\"\n",
        "    address_link = f\"https://ipfs.io/ipfs/{address_cid}\"\n",
        "\n",
        "    # Return the correct variables (photo_data_links can be a string or list)\n",
        "    return photo_data_links, property_photo_link, property_link, address_link\n",
        "\n",
        "\n",
        "def run_validate_and_upload():\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"npx\", \"-y\", \"@elephant-xyz/cli\", \"validate-and-upload\", \"output\", \"--output-csv\", \"photo-results.csv\"],\n",
        "            stdout=subprocess.DEVNULL,    # ховаємо stdout\n",
        "            stderr=subprocess.PIPE,       # ловимо stderr у буфер\n",
        "            check=True,\n",
        "            text=True,\n",
        "        )\n",
        "\n",
        "        photo_info = get_photo_info()\n",
        "        photo_group_cid, data_cid, html_link = photo_info[\"dataGroupCid\"], photo_info[\"dataCid\"], photo_info[\"htmlLink\"]\n",
        "\n",
        "        files_uploaded = count_upload_records()\n",
        "        data_ipfs_links = collect_data_ipfs_links(data_cid)\n",
        "        photo_data_links, property_photo_link, property_link, address_link = data_ipfs_links\n",
        "\n",
        "        print(\"✅ Upload done\\n\")\n",
        "        print(f\"{files_uploaded} files uploaded\\n\")\n",
        "\n",
        "        print(f\"Photo group CID: {photo_group_cid}\\n\")\n",
        "        print(f\"HTML link: {html_link}\\n\")\n",
        "\n",
        "        # Handle photo_data_links as either string or list\n",
        "        if isinstance(photo_data_links, list):\n",
        "            print(f\"Photo data IPFS links:\")\n",
        "            for i, link in enumerate(photo_data_links, 1):\n",
        "                print(f\"  Photo {i}: {link}\")\n",
        "        else:\n",
        "            print(f\"Photo data IPFS link: {photo_data_links}\")\n",
        "\n",
        "        print(f\"Relationship IPFS link: {property_photo_link}\")\n",
        "        print(f\"Property seed IPFS link: {property_link}\")\n",
        "        print(f\"Unnormalized address IPFS link: {address_link}\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Command failed (exit code {e.returncode}):\", file=sys.stderr)\n",
        "        print(e.stderr.strip(), file=sys.stderr)\n",
        "        sys.exit(e.returncode)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_validate_and_upload()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "usTSNRlN_LBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r output seed county"
      ],
      "metadata": {
        "id": "-RW_cXcQ8KI1",
        "outputId": "426e3d5b-2c52-4e17-a41f-fa73e95eccc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'output': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 5: Submit\n",
        "\n",
        "! pip3 install python-dotenv -q\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "\n",
        "def get_transaction_hash(path=\"transaction-status.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        first_row = next(reader, None)\n",
        "        if first_row is None:\n",
        "            raise ValueError(\"CSV file is empty\")\n",
        "        return first_row[\"transactionHash\"]\n",
        "\n",
        "\n",
        "def has_submit_errors(path=\"submit_errors.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        return next(reader, None) is not None\n",
        "\n",
        "\n",
        "def run_submit_to_contract():\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\n",
        "                \"npx\", \"-y\", \"@elephant-xyz/cli\", \"submit-to-contract\", \"photo-results.csv\",\n",
        "                \"--from-address\", \"0xefAd08946612A15d5De8D4Db7fc03556b6424075\",\n",
        "                \"--api-key\", \"f7e18cf6-5d07-4e4a-ae23-f27b812614e6\",\n",
        "                \"--domain\", \"oracles-69c46050.staircaseapi.com\",\n",
        "                \"--oracle-key-id\", \"7ad26e0b-67c9-4c2f-95a2-2792c7db5ac7\",\n",
        "            ],\n",
        "            stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.PIPE,\n",
        "            check=True,\n",
        "            text=True,\n",
        "        )\n",
        "        if has_submit_errors():\n",
        "            print(\"❌ Submit failed, please check submit_errors.csv for details\", file=sys.stderr)\n",
        "            return\n",
        "\n",
        "        transaction_hash = get_transaction_hash()\n",
        "        transaction_link = f\"https://polygonscan.com/tx/{transaction_hash}\"\n",
        "\n",
        "        print(\"✅ Submit done\\n\")\n",
        "        print(f\"Transaction link: {transaction_link}\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Command failed (exit code {e.returncode}):\", file=sys.stderr)\n",
        "        print(e.stderr.strip(), file=sys.stderr)\n",
        "        sys.exit(e.returncode)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_submit_to_contract()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pUsu2kFm_gmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c64ed3c-c348-4622-9513-f98918fc0d70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Submit done\n",
            "\n",
            "Transaction link: https://polygonscan.com/tx/0xb64df442346f8102a8756c83069ccf2af5db83362e40cac18f50261a2ff5df80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Photo Metadata Mining Process\n"
      ],
      "metadata": {
        "id": "t_sfdTo9tbP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cjRpTVubteBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 1: Prepare\n",
        "# @title  {\"vertical-output\":true}\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "import re\n",
        "import sys\n",
        "import csv\n",
        "import json\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from ctypes import c_void_p\n",
        "\n",
        "\n",
        "\n",
        "def cleanup_folders(base_path=\"/content\"):\n",
        "    \"\"\"\n",
        "    Remove specified folders and their contents.\n",
        "\n",
        "    Args:\n",
        "        base_path (str): Base path where folders are located (default: \"/content\")\n",
        "    \"\"\"\n",
        "    folders_to_remove = [\"output\", \"images\", \"seed\", \"county\", \"county-data\"]\n",
        "\n",
        "    for folder in folders_to_remove:\n",
        "        folder_path = os.path.join(base_path, folder)\n",
        "        if os.path.exists(folder_path):\n",
        "            shutil.rmtree(folder_path)\n",
        "\n",
        "def extract_images(parcel_id):\n",
        "    \"\"\"Extract JPG files from parcel zip, skip macOS files\"\"\"\n",
        "    zip_path = f\"/content/{parcel_id}.zip\"\n",
        "    extract_path = f\"images/{parcel_id}\"\n",
        "    temp_path = f\"/tmp/{parcel_id}_temp\"\n",
        "\n",
        "    if not os.path.exists(zip_path):\n",
        "        return None\n",
        "\n",
        "    os.makedirs(extract_path, exist_ok=True)\n",
        "    os.makedirs(temp_path, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        # Extract only JPG files, exclude macOS files\n",
        "        subprocess.run([\n",
        "            'unzip', '-j', '-o', zip_path, '-d', temp_path,\n",
        "            '*.jpg', '*.jpeg', '*.JPG', '*.JPEG',\n",
        "            '-x', '__MACOSX/*', '*.DS_Store'\n",
        "        ], capture_output=True, text=True)\n",
        "\n",
        "        extracted_count = 0\n",
        "        if os.path.exists(temp_path):\n",
        "            for file in os.listdir(temp_path):\n",
        "                if file.lower().endswith(('.jpg', '.jpeg')):\n",
        "                    source = os.path.join(temp_path, file)\n",
        "                    target = os.path.join(extract_path, file)\n",
        "                    if os.path.exists(source):\n",
        "                        shutil.copy2(source, target)\n",
        "                        extracted_count += 1\n",
        "\n",
        "        if os.path.exists(temp_path):\n",
        "            shutil.rmtree(temp_path)\n",
        "\n",
        "        return extract_path if extracted_count > 0 else None\n",
        "\n",
        "    except Exception:\n",
        "        if os.path.exists(temp_path):\n",
        "            shutil.rmtree(temp_path)\n",
        "        return None\n",
        "\n",
        "\n",
        "def ensure_directory(file_path):\n",
        "    \"\"\"Ensure the directory for the file exists\"\"\"\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if directory and not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "\n",
        "def create_parcel_folder(parcel_id):\n",
        "    # Create folder name based on parcel_id\n",
        "    clean_parcel_id = re.sub(r\"[^\\w\\-_]\", \"_\", str(parcel_id))\n",
        "    folder_name = f\"output/{clean_parcel_id}\"\n",
        "    ensure_directory(folder_name + \"/\")\n",
        "    return folder_name\n",
        "\n",
        "\n",
        "def install_photo_meta_data_ai():\n",
        "    \"\"\"Install photo-meta-data-ai package from GitHub\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run([\n",
        "            sys.executable, '-m', 'pip', 'install',\n",
        "            '--force-reinstall', '--no-cache-dir',\n",
        "            'git+https://github.com/elephant-xyz/photo-meta-data-ai.git'\n",
        "        ], capture_output=True, text=True, timeout=300)\n",
        "\n",
        "        with open('/content/install_log.txt', 'w') as f:\n",
        "            f.write(\"STDOUT:\\n\")\n",
        "            f.write(result.stdout)\n",
        "            f.write(\"\\nSTDERR:\\n\")\n",
        "            f.write(result.stderr)\n",
        "            f.write(f\"\\nReturn code: {result.returncode}\")\n",
        "\n",
        "        return result.returncode == 0\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        return False\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def copy_images_to_output():\n",
        "   \"\"\"Copy images from images/<parcel_id>/ to output/<parcel_id>/\"\"\"\n",
        "   try:\n",
        "       source_dir = \"/content/images\"\n",
        "       output_dir = \"/content/output\"\n",
        "\n",
        "       if os.path.exists(source_dir):\n",
        "           shutil.copytree(source_dir, output_dir, dirs_exist_ok=True)\n",
        "           return True\n",
        "       return False\n",
        "   except:\n",
        "       return False\n",
        "\n",
        "\n",
        "def extract_datacids_from_csv(csv_path):\n",
        "    \"\"\"Extract all dataCIDs from a CSV file.\"\"\"\n",
        "    datacids = []\n",
        "\n",
        "    with open(csv_path, 'r') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            if 'dataCid' in row and row['dataCid']:\n",
        "                datacid = row['dataCid'].strip()\n",
        "                if datacid:\n",
        "                    datacids.append(datacid)\n",
        "\n",
        "    return datacids\n",
        "\n",
        "\n",
        "def traverse_and_download(cids, destination_folder):\n",
        "    \"\"\"\n",
        "    Download CIDs and all related CIDs by traversing relationships.\n",
        "    Creates folder structure: destination_folder/cid/ for each CID in the list.\n",
        "\n",
        "    Args:\n",
        "        cids (list): List of root CIDs to start traversing from\n",
        "        destination_folder (str): The destination folder name\n",
        "    \"\"\"\n",
        "    total_downloaded = 0\n",
        "\n",
        "    for cid in cids:\n",
        "        downloaded = set()\n",
        "\n",
        "        # Create folder structure for this CID\n",
        "        main_folder = Path(f\"{destination_folder}/{cid}\")\n",
        "        main_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        def traverse_cid(current_cid):\n",
        "            \"\"\"Recursively fetch CID and traverse relationships\"\"\"\n",
        "            if current_cid in downloaded:\n",
        "                return\n",
        "\n",
        "\n",
        "\n",
        "            try:\n",
        "                response = requests.get(f\"https://ipfs.io/ipfs/{current_cid}\", timeout=30)\n",
        "                data = response.json()\n",
        "\n",
        "                # Save the JSON file\n",
        "                file_path = main_folder / f\"{current_cid}.json\"\n",
        "                with open(file_path, 'w') as f:\n",
        "                    json.dump(data, f, indent=2)\n",
        "\n",
        "                downloaded.add(current_cid)\n",
        "\n",
        "                # Look for relationships\n",
        "                if \"relationships\" in data:\n",
        "                    for key, value in data[\"relationships\"].items():\n",
        "                        if value is None:\n",
        "                            # Skip null relationships\n",
        "                            continue\n",
        "                        elif isinstance(value, dict) and \"/\" in value:\n",
        "                            # Single CID reference\n",
        "                            related_cid = value[\"/\"]\n",
        "                            traverse_cid(related_cid)\n",
        "                        elif isinstance(value, list):\n",
        "                            # Array of CID references\n",
        "                            for i, item in enumerate(value):\n",
        "                                if isinstance(item, dict) and \"/\" in item:\n",
        "                                    related_cid = item[\"/\"]\n",
        "                                    traverse_cid(related_cid)\n",
        "\n",
        "                # Look for \"from\" and \"to\" fields\n",
        "                for field in [\"from\", \"to\"]:\n",
        "                    if field in data:\n",
        "                        value = data[field]\n",
        "                        if isinstance(value, dict) and \"/\" in value:\n",
        "                            # Single CID reference\n",
        "                            related_cid = value[\"/\"]\n",
        "                            traverse_cid(related_cid)\n",
        "                        elif isinstance(value, list):\n",
        "                            # Array of CID references\n",
        "                            for item in value:\n",
        "                                if isinstance(item, dict) and \"/\" in item:\n",
        "                                    related_cid = item[\"/\"]\n",
        "                                    traverse_cid(related_cid)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading CID {current_cid}: {e}\")\n",
        "\n",
        "        # Start traversal for this root CID\n",
        "        traverse_cid(cid)\n",
        "\n",
        "        total_downloaded += len(downloaded)\n",
        "\n",
        "\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def rename_and_update_references(cids, parent_folder):\n",
        "    \"\"\"\n",
        "    Rename JSON files to meaningful names and update all CID references to relative paths.\n",
        "    Keep the root CID filename unchanged. Can process single CID or list of CIDs.\n",
        "\n",
        "    Args:\n",
        "        cids (str or list): Single CID or list of CIDs to process\n",
        "        parent_folder (str): The parent folder path (e.g., 'seed')\n",
        "    \"\"\"\n",
        "    # Convert single CID to list for uniform processing\n",
        "    if isinstance(cids, str):\n",
        "        cids = [cids]\n",
        "\n",
        "    total_processed = 0\n",
        "\n",
        "    for cid in cids:\n",
        "\n",
        "        # Construct the full folder path\n",
        "        folder = Path(f\"{parent_folder}/{cid}\")\n",
        "\n",
        "        if not folder.exists():\n",
        "            continue\n",
        "\n",
        "        # The root file should match the CID\n",
        "        root_file = folder / f\"{cid}.json\"\n",
        "\n",
        "        if not root_file.exists():\n",
        "            continue\n",
        "\n",
        "        # Track CID to new filename mapping for this folder\n",
        "        cid_to_filename = {}\n",
        "        processed_files = set()\n",
        "\n",
        "        # Track naming counters to handle duplicates\n",
        "        name_counters = {}\n",
        "\n",
        "        # Root CID keeps its original name\n",
        "        cid_to_filename[cid] = f\"{cid}.json\"\n",
        "\n",
        "        def get_meaningful_name(file_cid, relationship_key=None, file_data=None, index=None):\n",
        "          \"\"\"Generate meaningful filename based on content or relationship\"\"\"\n",
        "          base_name = None\n",
        "\n",
        "          # Always prioritize content-based naming for specific types\n",
        "          if file_data:\n",
        "              if \"parcel_identifier\" in file_data:\n",
        "                  base_name = \"property\"\n",
        "              elif \"parcel_id\" in file_data:\n",
        "                  base_name = \"property_seed\"\n",
        "              elif \"space_type\" in file_data:\n",
        "                  base_name = \"layout\"\n",
        "              elif \"full_address\" in file_data:\n",
        "                  base_name = \"address_data\"\n",
        "              elif \"from\" in file_data or \"to\" in file_data:\n",
        "                  base_name = \"connection\"\n",
        "\n",
        "          # Only use relationship key if no content pattern matched\n",
        "          if not base_name and relationship_key:\n",
        "              if index is not None:\n",
        "                  base_name = f\"{relationship_key}_{index}\"\n",
        "              else:\n",
        "                  base_name = relationship_key\n",
        "\n",
        "          # Final fallback to shortened CID\n",
        "          if not base_name:\n",
        "              base_name = file_cid[:8]\n",
        "\n",
        "          # Handle duplicate names by adding counter\n",
        "          if base_name in name_counters:\n",
        "              name_counters[base_name] += 1\n",
        "              final_name = f\"{base_name}_{name_counters[base_name]}\"\n",
        "          else:\n",
        "              name_counters[base_name] = 0\n",
        "              final_name = base_name\n",
        "\n",
        "          return f\"{final_name}.json\"\n",
        "\n",
        "        def process_file(file_cid, relationship_key=None, index=None):\n",
        "            \"\"\"Process a single file and its references\"\"\"\n",
        "            if file_cid in processed_files:\n",
        "                return cid_to_filename.get(file_cid)\n",
        "\n",
        "            file_path = folder / f\"{file_cid}.json\"\n",
        "            if not file_path.exists():\n",
        "                return None\n",
        "\n",
        "            # Load file content\n",
        "            with open(file_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            # Determine new filename (skip if it's the root CID)\n",
        "            if file_cid != cid:\n",
        "                new_filename = get_meaningful_name(file_cid, relationship_key, data, index)\n",
        "                cid_to_filename[file_cid] = new_filename\n",
        "\n",
        "            processed_files.add(file_cid)\n",
        "\n",
        "            # Process relationships in the current file\n",
        "            if \"relationships\" in data:\n",
        "                for key, value in data[\"relationships\"].items():\n",
        "                    if value is None:\n",
        "                        # Skip null relationships\n",
        "                        continue\n",
        "                    elif isinstance(value, dict) and \"/\" in value:\n",
        "                        # Single CID reference\n",
        "                        related_cid = value[\"/\"]\n",
        "                        if not related_cid.startswith(\"./\"):  # Only process actual CIDs, not already converted paths\n",
        "                            process_file(related_cid, key)\n",
        "                    elif isinstance(value, list):\n",
        "                        # Multiple CID references\n",
        "                        for i, item in enumerate(value):\n",
        "                            if isinstance(item, dict) and \"/\" in item:\n",
        "                                related_cid = item[\"/\"]\n",
        "                                if not related_cid.startswith(\"./\"):  # Only process actual CIDs\n",
        "                                    process_file(related_cid, key, i)\n",
        "\n",
        "            # Process \"from\" and \"to\" fields\n",
        "            for field in [\"from\", \"to\"]:\n",
        "                if field in data:\n",
        "                    value = data[field]\n",
        "                    if isinstance(value, dict) and \"/\" in value:\n",
        "                        related_cid = value[\"/\"]\n",
        "                        if not related_cid.startswith(\"./\"):  # Only process actual CIDs\n",
        "                            process_file(related_cid, field)\n",
        "                    elif isinstance(value, list):\n",
        "                        for i, item in enumerate(value):\n",
        "                            if isinstance(item, dict) and \"/\" in item:\n",
        "                                related_cid = item[\"/\"]\n",
        "                                if not related_cid.startswith(\"./\"):  # Only process actual CIDs\n",
        "                                    process_file(related_cid, field, i)\n",
        "\n",
        "            return cid_to_filename.get(file_cid)\n",
        "\n",
        "        # Start processing from root file\n",
        "        process_file(cid)\n",
        "\n",
        "        # Now update all references and rename files\n",
        "        for file_cid, new_filename in cid_to_filename.items():\n",
        "            old_file_path = folder / f\"{file_cid}.json\"\n",
        "            new_file_path = folder / new_filename\n",
        "\n",
        "            if not old_file_path.exists():\n",
        "                continue\n",
        "\n",
        "            # Load and update file content\n",
        "            with open(old_file_path, 'r') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            # Update references in this file\n",
        "            if \"relationships\" in data:\n",
        "                for key, value in data[\"relationships\"].items():\n",
        "                    if isinstance(value, dict) and \"/\" in value:\n",
        "                        # Single CID reference\n",
        "                        referenced_cid = value[\"/\"]\n",
        "                        if referenced_cid in cid_to_filename and not referenced_cid.startswith(\"./\"):\n",
        "                            data[\"relationships\"][key] = {\"/\": f\"./{cid_to_filename[referenced_cid]}\"}\n",
        "                    elif isinstance(value, list):\n",
        "                        # Multiple CID references\n",
        "                        updated_list = []\n",
        "                        for item in value:\n",
        "                            if isinstance(item, dict) and \"/\" in item:\n",
        "                                referenced_cid = item[\"/\"]\n",
        "                                if referenced_cid in cid_to_filename and not referenced_cid.startswith(\"./\"):\n",
        "                                    updated_list.append({\"/\": f\"./{cid_to_filename[referenced_cid]}\"})\n",
        "                                else:\n",
        "                                    updated_list.append(item)\n",
        "                            else:\n",
        "                                updated_list.append(item)\n",
        "                        data[\"relationships\"][key] = updated_list\n",
        "\n",
        "            # Update \"from\" and \"to\" fields\n",
        "            for field in [\"from\", \"to\"]:\n",
        "                if field in data:\n",
        "                    value = data[field]\n",
        "                    if isinstance(value, dict) and \"/\" in value:\n",
        "                        referenced_cid = value[\"/\"]\n",
        "                        if referenced_cid in cid_to_filename and not referenced_cid.startswith(\"./\"):\n",
        "                            data[field] = {\"/\": f\"./{cid_to_filename[referenced_cid]}\"}\n",
        "                    elif isinstance(value, list):\n",
        "                        updated_list = []\n",
        "                        for item in value:\n",
        "                            if isinstance(item, dict) and \"/\" in item:\n",
        "                                referenced_cid = item[\"/\"]\n",
        "                                if referenced_cid in cid_to_filename and not referenced_cid.startswith(\"./\"):\n",
        "                                    updated_list.append({\"/\": f\"./{cid_to_filename[referenced_cid]}\"})\n",
        "                                else:\n",
        "                                    updated_list.append(item)\n",
        "                            else:\n",
        "                                updated_list.append(item)\n",
        "                        data[field] = updated_list\n",
        "\n",
        "            # Save updated content to new file\n",
        "            with open(new_file_path, 'w') as f:\n",
        "                json.dump(data, f, indent=2)\n",
        "\n",
        "            # Remove old file if name changed\n",
        "            if old_file_path != new_file_path:\n",
        "                old_file_path.unlink()\n",
        "\n",
        "        total_processed += len(processed_files)\n",
        "\n",
        "import json\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "import json\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "def copy_cid_to_parcel_structure(source_folder, target_folder_prefix):\n",
        "    \"\"\"\n",
        "    Copy folders from folder/CID/data structure to folder-parcel/parcelid/data structure.\n",
        "\n",
        "    Args:\n",
        "        source_folder (str): Source folder containing CID subfolders (e.g., 'seed')\n",
        "        target_folder_prefix (str): Target folder prefix (e.g., 'seed-parcel')\n",
        "    \"\"\"\n",
        "    source_path = Path(source_folder)\n",
        "\n",
        "    if not source_path.exists():\n",
        "        return\n",
        "\n",
        "    processed_count = 0\n",
        "    error_count = 0\n",
        "\n",
        "    # Iterate through all CID folders in source\n",
        "    for cid_folder in source_path.iterdir():\n",
        "        if not cid_folder.is_dir():\n",
        "            continue\n",
        "\n",
        "        cid = cid_folder.name\n",
        "\n",
        "        # Look for the root JSON file (should match CID name)\n",
        "        root_file = cid_folder / f\"{cid}.json\"\n",
        "\n",
        "        if not root_file.exists():\n",
        "            error_count += 1\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Load root file to find parcel_id\n",
        "            with open(root_file, 'r') as f:\n",
        "                root_data = json.load(f)\n",
        "\n",
        "            # Extract parcel_id - check multiple possible field names\n",
        "            parcel_id = None\n",
        "            for field in ['parcel_id', 'parcel_identifier', 'parcelId', 'parcelIdentifier']:\n",
        "                if field in root_data:\n",
        "                    parcel_id = root_data[field]\n",
        "                    break\n",
        "\n",
        "            # If not in root, check for property.json or files with parcel info\n",
        "            if not parcel_id:\n",
        "                # Look for property.json or files containing parcel info\n",
        "                for json_file in cid_folder.glob(\"*.json\"):\n",
        "                    if json_file.name == f\"{cid}.json\":\n",
        "                        continue  # Skip root file, already checked\n",
        "\n",
        "                    try:\n",
        "                        with open(json_file, 'r') as f:\n",
        "                            data = json.load(f)\n",
        "\n",
        "                        for field in ['parcel_id', 'parcel_identifier', 'parcelId', 'parcelIdentifier']:\n",
        "                            if field in data:\n",
        "                                parcel_id = data[field]\n",
        "                                break\n",
        "\n",
        "                        if parcel_id:\n",
        "                            break\n",
        "                    except (json.JSONDecodeError, Exception) as e:\n",
        "                        continue\n",
        "\n",
        "            if not parcel_id:\n",
        "                error_count += 1\n",
        "                continue\n",
        "\n",
        "            # Remove hyphens from parcel_id for folder name\n",
        "            clean_parcel_id = str(parcel_id).replace('-', '')\n",
        "\n",
        "            # Create target folder structure\n",
        "            target_folder = Path(f\"{target_folder_prefix}\")\n",
        "            target_cid_folder = target_folder / clean_parcel_id\n",
        "\n",
        "            # Create target directory if it doesn't exist\n",
        "            target_cid_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            # Copy all files from source CID folder to target parcel folder\n",
        "            for item in cid_folder.iterdir():\n",
        "                target_item = target_cid_folder / item.name\n",
        "\n",
        "                if item.is_file():\n",
        "                    shutil.copy2(item, target_item)\n",
        "                elif item.is_dir():\n",
        "                    shutil.copytree(item, target_item, dirs_exist_ok=True)\n",
        "\n",
        "            processed_count += 1\n",
        "\n",
        "        except Exception as e:\n",
        "            error_count += 1\n",
        "            continue\n",
        "\n",
        "    return processed_count, error_count\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    parcel_id = \"52434205310037080\" # @param {\"type\":\"string\"}\n",
        "    cleanup_folders()\n",
        "    extract_images(parcel_id)\n",
        "    create_parcel_folder(parcel_id)\n",
        "    install_photo_meta_data_ai()\n",
        "    copy_images_to_output()\n",
        "    datacid = extract_datacids_from_csv(\"seed-results.csv\")\n",
        "    countydatacid = extract_datacids_from_csv(\"county-results.csv\")\n",
        "    traverse_and_download(datacid, \"seed\")\n",
        "    traverse_and_download(countydatacid, \"county\")\n",
        "    rename_and_update_references(datacid, \"seed\")\n",
        "    rename_and_update_references(countydatacid, \"county\")\n",
        "    copy_cid_to_parcel_structure(\"county\",\"county-data\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "V2DUdUwI5rWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 2: Transform\n",
        "! pip3 install python-dotenv -q\n",
        "import subprocess\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import csv\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "def copy_csv(source_path, destination_path):\n",
        "    \"\"\"\n",
        "    Copy a CSV file from source to destination.\n",
        "\n",
        "    Args:\n",
        "        source_path (str): Path to the source CSV file\n",
        "        destination_path (str): Path to the destination CSV file\n",
        "\n",
        "    Returns:\n",
        "        bool: True if successful, False otherwise\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check if source file exists\n",
        "        if not os.path.exists(source_path):\n",
        "            print(f\"Error: Source file '{source_path}' does not exist.\")\n",
        "            return False\n",
        "\n",
        "        # Create destination directory if it doesn't exist\n",
        "        dest_dir = os.path.dirname(destination_path)\n",
        "        if dest_dir and not os.path.exists(dest_dir):\n",
        "            os.makedirs(dest_dir)\n",
        "\n",
        "        # Copy the file\n",
        "        shutil.copy2(source_path, destination_path)\n",
        "        print(f\"Successfully copied '{source_path}' to '{destination_path}'\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error copying file: {e}\")\n",
        "        return False\n",
        "\n",
        "def get_photo_cid_and_html_link(path=\"photometadata-results.csv\"):\n",
        "    \"\"\"Get photo CID and HTML link from upload results CSV\"\"\"\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        first_row = next(reader, None)\n",
        "        if first_row is None:\n",
        "            raise ValueError(\"CSV file is empty\")\n",
        "        return first_row[\"dataGroupCid\"], first_row[\"htmlLink\"]\n",
        "\n",
        "\n",
        "def has_submit_errors(path=\"submit_errors.csv\"):\n",
        "    \"\"\"\n",
        "    Returns True if submit_errors.csv has at least one row (after header).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "            reader = csv.DictReader(csvfile)\n",
        "            return next(reader, None) is not None\n",
        "    except FileNotFoundError:\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "def process_photo_data(input_dir=\"output\", property_filename=\"my_property.json\"):\n",
        "    \"\"\"Step 1: Process photo data\"\"\"\n",
        "    os.chdir(\"/content\")\n",
        "\n",
        "    try:\n",
        "        cmd = f\"process-photo-data --input-dir {input_dir} --property-filename {property_filename}\"\n",
        "        subprocess.run(cmd, shell=True, check=True)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "\n",
        "def copy_group_to_output(output_folder=\"output\", seed_folder=\"seed\", rename_to_cid=True):\n",
        "\n",
        "    if not os.path.exists(output_folder) or not os.path.exists(seed_folder):\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        # Get all parcel ID folders in output\n",
        "        output_parcel_folders = [f for f in os.listdir(output_folder)\n",
        "                               if os.path.isdir(os.path.join(output_folder, f))]\n",
        "\n",
        "        # Get all CID folders in seed\n",
        "        seed_cid_folders = [f for f in os.listdir(seed_folder)\n",
        "                          if os.path.isdir(os.path.join(seed_folder, f))]\n",
        "\n",
        "        # Create mapping by reading JSON files in seed folders\n",
        "        parcel_to_cid_mapping = {}\n",
        "\n",
        "        for cid in seed_cid_folders:\n",
        "            cid_folder_path = os.path.join(seed_folder, cid)\n",
        "\n",
        "            # Look for JSON files in the CID folder\n",
        "            for file in os.listdir(cid_folder_path):\n",
        "                if file.endswith('.json'):\n",
        "                    json_file_path = os.path.join(cid_folder_path, file)\n",
        "                    try:\n",
        "                        with open(json_file_path, 'r') as f:\n",
        "                            data = json.load(f)\n",
        "\n",
        "                        # Look for parcel_id or parcel_identifier in the JSON data\n",
        "                        parcel_id = None\n",
        "                        if 'parcel_id' in data:\n",
        "                            parcel_id = str(data['parcel_id']).strip()\n",
        "                        elif 'parcel_identifier' in data:\n",
        "                            parcel_id = str(data['parcel_identifier']).strip()\n",
        "\n",
        "                        if parcel_id:\n",
        "                            # Normalize parcel ID by removing dashes\n",
        "                            normalized_parcel_id = parcel_id.replace('-', '')\n",
        "                            if normalized_parcel_id:\n",
        "                                parcel_to_cid_mapping[normalized_parcel_id] = cid\n",
        "                                break\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "        # Process each parcel folder\n",
        "        for parcel_id in output_parcel_folders:\n",
        "            # Normalize the parcel folder name (remove dashes) to match our mapping\n",
        "            normalized_parcel_id = parcel_id.replace('-', '')\n",
        "\n",
        "            # Find corresponding CID\n",
        "            corresponding_cid = parcel_to_cid_mapping.get(normalized_parcel_id)\n",
        "\n",
        "            if corresponding_cid and corresponding_cid in seed_cid_folders:\n",
        "                # Paths\n",
        "                output_parcel_path = os.path.join(output_folder, parcel_id)\n",
        "                seed_cid_path = os.path.join(seed_folder, corresponding_cid)\n",
        "\n",
        "                # Copy all content from seed CID folder to output parcel folder\n",
        "                for item in os.listdir(seed_cid_path):\n",
        "                    source_path = os.path.join(seed_cid_path, item)\n",
        "                    dest_path = os.path.join(output_parcel_path, item)\n",
        "\n",
        "                    if os.path.isfile(source_path):\n",
        "                        shutil.copy2(source_path, dest_path)\n",
        "                    elif os.path.isdir(source_path):\n",
        "                        if os.path.exists(dest_path):\n",
        "                            shutil.rmtree(dest_path)\n",
        "                        shutil.copytree(source_path, dest_path)\n",
        "\n",
        "                # Rename parcel ID folder to CID if requested\n",
        "                if rename_to_cid:\n",
        "                    new_output_cid_path = os.path.join(output_folder, corresponding_cid)\n",
        "\n",
        "                    if not os.path.exists(new_output_cid_path):\n",
        "                        os.rename(output_parcel_path, new_output_cid_path)\n",
        "                    else:\n",
        "                        # If CID folder already exists, merge content and remove parcel folder\n",
        "                        for item in os.listdir(output_parcel_path):\n",
        "                            source_path = os.path.join(output_parcel_path, item)\n",
        "                            dest_path = os.path.join(new_output_cid_path, item)\n",
        "\n",
        "                            if os.path.isfile(source_path):\n",
        "                                shutil.copy2(source_path, dest_path)\n",
        "                            elif os.path.isdir(source_path):\n",
        "                                if os.path.exists(dest_path):\n",
        "                                    shutil.rmtree(dest_path)\n",
        "                                shutil.copytree(source_path, dest_path)\n",
        "\n",
        "                        shutil.rmtree(output_parcel_path)\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "def run_validate_and_upload():\n",
        "    \"\"\"Run validation and upload process\"\"\"\n",
        "    try:\n",
        "\n",
        "        subprocess.run(\n",
        "            [\"npx\", \"-y\", \"@elephant-xyz/cli\", \"validate-and-upload\", \"output\", \"--output-csv\", \"photometadata-results.csv\"],\n",
        "            stdout=subprocess.DEVNULL,    # hide stdout\n",
        "            stderr=subprocess.PIPE,       # capture stderr\n",
        "            check=True,\n",
        "            text=True                     # stderr as string\n",
        "        )\n",
        "\n",
        "        # If there are recorded errors - stop execution\n",
        "\n",
        "\n",
        "        # Otherwise - read results\n",
        "        photo_group_cid, html_link = get_photo_cid_and_html_link()\n",
        "        print(\"✅ Transform done\\n\")\n",
        "        print(f\"Photo group CID: {photo_group_cid}\\n\")\n",
        "        print(f\"HTML link: {html_link}\")\n",
        "        return True\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # handle command execution errors\n",
        "        print(f\"Command failed (exit code {e.returncode}):\", file=sys.stderr)\n",
        "        if e.stderr:\n",
        "            print(e.stderr.strip(), file=sys.stderr)\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Validation and upload failed: {str(e)}\")\n",
        "        return False\n",
        "def run_shell_commands():\n",
        "    \"\"\"\n",
        "    Execute shell commands: bucket-manager, unzip-county-data, upload-to-s3\n",
        "\n",
        "    Returns:\n",
        "        bool: True if all commands succeeded, False if any failed\n",
        "    \"\"\"\n",
        "    commands = [\n",
        "        \"bucket-manager\",\n",
        "        \"upload-to-s3\",\n",
        "        \"photo-categorizer\",\n",
        "        \"ai-analyzer --local-folders --parallel-categories --all-properties --county-data-dir ./county-data \",\n",
        "        \"fix-schema-validation\"\n",
        "    ]\n",
        "\n",
        "    for command in commands:\n",
        "        try:\n",
        "            subprocess.run(command, shell=True, check=True, capture_output=True, text=True)\n",
        "        except subprocess.CalledProcessError:\n",
        "            return False\n",
        "        except Exception:\n",
        "            return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main processing pipeline\"\"\"\n",
        "    os.chdir(\"/content\")\n",
        "    run_shell_commands()\n",
        "    copy_group_to_output(\"output\",\"county\",False)\n",
        "    copy_group_to_output(\"output\",\"seed\")\n",
        "    run_validate_and_upload()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "b99RYV_tNCvO",
        "outputId": "e5d7f77f-3bd7-479a-886a-8249fa9880f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Transform done\n",
            "\n",
            "Photo group CID: bafkreih226p5vjhx33jwgq7trblyplfw7yhkununuuahgpfok3hnh5mjwq\n",
            "\n",
            "HTML link: http://dweb.link/ipfs/bafybeid3unil7orix7cqadb6xpkt7m74bhb5xwez22k2jkyhxw7mvwtunm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 3: Validate\n",
        "! pip3 install python-dotenv -q\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "\n",
        "def get_photo_cid_and_html_link(path=\"/content/photometadata-results.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        first_row = next(reader, None)\n",
        "        if first_row is None:\n",
        "            raise ValueError(\"CSV file is empty\")\n",
        "        return first_row[\"dataGroupCid\"], first_row[\"htmlLink\"]\n",
        "\n",
        "\n",
        "def has_submit_errors(path=\"/content/submit_errors.csv\"):\n",
        "    \"\"\"\n",
        "    Повертає True, якщо у файлі submit_errors.csv є хоча б один рядок (після заголовку).\n",
        "    \"\"\"\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        return next(reader, None) is not None\n",
        "\n",
        "\n",
        "def run_validate_and_upload():\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"npx\", \"-y\", \"@elephant-xyz/cli\", \"validate-and-upload\", \"output\", \"--output-csv\", \"photo-results.csv\"],\n",
        "            stdout=subprocess.DEVNULL,    # ховаємо stdout\n",
        "            stderr=subprocess.PIPE,       # ловимо stderr у буфер\n",
        "            check=True,\n",
        "            text=True                     # stderr як рядок\n",
        "        )\n",
        "\n",
        "\n",
        "        # Інакше — читаємо результати\n",
        "        photometa_group_cid, html_link = get_photo_cid_and_html_link()\n",
        "        print(\"✅ Validate done\\n\")\n",
        "        print(f\"Photometadata group CID: {photometa_group_cid}\\n\")\n",
        "        print(f\"HTML link: {html_link}\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        # обробка помилок виконання команди\n",
        "        print(f\"Command failed (exit code {e.returncode}):\", file=sys.stderr)\n",
        "        print(e.stderr.strip(), file=sys.stderr)\n",
        "        sys.exit(e.returncode)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_validate_and_upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "4zUSb5JdR5WO",
        "outputId": "3423e459-6d59-4f5b-bd1e-976b3e835e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Validate done\n",
            "\n",
            "Photometadata group CID: bafkreih226p5vjhx33jwgq7trblyplfw7yhkununuuahgpfok3hnh5mjwq\n",
            "\n",
            "HTML link: http://dweb.link/ipfs/bafybeicr3coifenubbuawewkrpzonm44z4strnumegkjpsmcqlupvvhr7a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kxPwhAaBtbsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 4: Upload\n",
        "! pip3 install python-dotenv requests -q\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "import requests\n",
        "\n",
        "\n",
        "def get_photo_info(path=\"photometadata-results.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        first_row = next(reader, None)\n",
        "        if first_row is None:\n",
        "            raise ValueError(\"CSV file is empty\")\n",
        "        return first_row\n",
        "\n",
        "\n",
        "def has_submit_errors(path=\"submit_errors.csv\"):\n",
        "    \"\"\"\n",
        "    Повертає True, якщо у файлі submit_errors.csv є хоча б один рядок (після заголовку).\n",
        "    \"\"\"\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        return next(reader, None) is not None\n",
        "\n",
        "\n",
        "def count_upload_records(path=\"photometadata-results.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        return sum(1 for _ in reader)\n",
        "\n",
        "\n",
        "def collect_data_ipfs_links(data_cid):\n",
        "    # Handle data_cid as either a single CID or a list of CIDs\n",
        "    if isinstance(data_cid, list):\n",
        "        photo_data_links = [f\"https://ipfs.io/ipfs/{cid}\" for cid in data_cid]\n",
        "        # Use the first CID to get the structure data\n",
        "        photo_data = requests.get(photo_data_links[0]).json()\n",
        "    else:\n",
        "        photo_data_links = f\"https://ipfs.io/ipfs/{data_cid}\"\n",
        "        photo_data = requests.get(photo_data_links).json()\n",
        "\n",
        "    # Extract property seed CID from the correct relationship\n",
        "    property_photo_cid = photo_data[\"relationships\"][\"property_has_file\"][0][\"/\"]  # Access first item in list\n",
        "    property_photo_link = f\"https://ipfs.io/ipfs/{property_photo_cid}\"  # Fixed variable name\n",
        "\n",
        "    # Get property seed data\n",
        "    property_seed_data = requests.get(property_photo_link).json()  # Fixed variable name\n",
        "\n",
        "    # Extract property and address CIDs\n",
        "    property_cid, address_cid = property_seed_data[\"from\"][\"/\"], property_seed_data[\"to\"][\"/\"]\n",
        "\n",
        "    # Create links\n",
        "    property_link = f\"https://ipfs.io/ipfs/{property_cid}\"\n",
        "    address_link = f\"https://ipfs.io/ipfs/{address_cid}\"\n",
        "\n",
        "    # Return the correct variables (photo_data_links can be a string or list)\n",
        "    return photo_data_links, property_photo_link, property_link, address_link\n",
        "\n",
        "\n",
        "def run_validate_and_upload():\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"npx\", \"-y\", \"@elephant-xyz/cli\", \"validate-and-upload\", \"output\", \"--output-csv\", \"photometadata-results.csv\"],\n",
        "            stdout=subprocess.DEVNULL,    # ховаємо stdout\n",
        "            stderr=subprocess.PIPE,       # ловимо stderr у буфер\n",
        "            check=True,\n",
        "            text=True,\n",
        "        )\n",
        "\n",
        "        photo_info = get_photo_info()\n",
        "        photo_group_cid, data_cid, html_link = photo_info[\"dataGroupCid\"], photo_info[\"dataCid\"], photo_info[\"htmlLink\"]\n",
        "\n",
        "        files_uploaded = count_upload_records()\n",
        "\n",
        "        data_ipfs_links = collect_data_ipfs_links(data_cid)\n",
        "        photo_data_links, property_photo_link, property_link, address_link = data_ipfs_links\n",
        "\n",
        "        print(\"✅ Upload done\\n\")\n",
        "        print(f\"{files_uploaded} files uploaded\\n\")\n",
        "\n",
        "        print(f\"Photometadata group CID: {photo_group_cid}\\n\")\n",
        "        print(f\"HTML link: {html_link}\\n\")\n",
        "\n",
        "        # Handle photo_data_links as either string or list\n",
        "        if isinstance(photo_data_links, list):\n",
        "            print(f\"Photo data IPFS links:\")\n",
        "            for i, link in enumerate(photo_data_links, 1):\n",
        "                print(f\"  Photo {i}: {link}\")\n",
        "        else:\n",
        "            print(f\"Photo data IPFS link: {photo_data_links}\")\n",
        "\n",
        "        print(f\"Relationship IPFS link: {property_photo_link}\")\n",
        "        print(f\"Property IPFS link: {property_link}\")\n",
        "\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Command failed (exit code {e.returncode}):\", file=sys.stderr)\n",
        "        print(e.stderr.strip(), file=sys.stderr)\n",
        "        sys.exit(e.returncode)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_validate_and_upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "fz6D2FatR_LC",
        "outputId": "4098d44d-de69-45d0-cba9-92e1df2c5cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Upload done\n",
            "\n",
            "1 files uploaded\n",
            "\n",
            "Photometadata group CID: bafkreih226p5vjhx33jwgq7trblyplfw7yhkununuuahgpfok3hnh5mjwq\n",
            "\n",
            "HTML link: http://dweb.link/ipfs/bafybeigmqhc3xnnrhuob6t7xv4b7bffe35rxgc6zb37u7ftcqzmirrixke\n",
            "\n",
            "Photo data IPFS link: https://ipfs.io/ipfs/bafkreie7yignhnctd3i3h5n2pff3xhnq72x4c5i4yzcw244pdvbil77w6u\n",
            "Relationship IPFS link: https://ipfs.io/ipfs/bafkreia3do6r7w6tgcvcjbyviz77tnoymg3pcjs7rpxztsgppc75ytkkm4\n",
            "Property IPFS link: https://ipfs.io/ipfs/bafkreifb6el25q5wl4n5gsiwdojmmxn67m6ez3xmjtprwz4cww7m7kwjvu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Step 5: Submit\n",
        "\n",
        "! pip3 install python-dotenv -q\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import csv\n",
        "\n",
        "\n",
        "def get_transaction_hash(path=\"transaction-status.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        first_row = next(reader, None)\n",
        "        if first_row is None:\n",
        "            raise ValueError(\"CSV file is empty\")\n",
        "        return first_row[\"transactionHash\"]\n",
        "\n",
        "\n",
        "def has_submit_errors(path=\"submit_errors.csv\"):\n",
        "    with open(path, newline='', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        return next(reader, None) is not None\n",
        "\n",
        "\n",
        "def run_submit_to_contract():\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\n",
        "                \"npx\", \"-y\", \"@elephant-xyz/cli\", \"submit-to-contract\", \"photometadata-results.csv\",\n",
        "                \"--from-address\", \"0xefAd08946612A15d5De8D4Db7fc03556b6424075\",\n",
        "                \"--api-key\", \"f7e18cf6-5d07-4e4a-ae23-f27b812614e6\",\n",
        "                \"--domain\", \"oracles-69c46050.staircaseapi.com\",\n",
        "                \"--oracle-key-id\", \"7ad26e0b-67c9-4c2f-95a2-2792c7db5ac7\",\n",
        "            ],\n",
        "            stdout=subprocess.DEVNULL,\n",
        "            stderr=subprocess.PIPE,\n",
        "            check=True,\n",
        "            text=True,\n",
        "        )\n",
        "        if has_submit_errors():\n",
        "            print(\"❌ Submit failed, please check submit_errors.csv for details\", file=sys.stderr)\n",
        "            return\n",
        "\n",
        "        transaction_hash = get_transaction_hash()\n",
        "        transaction_link = f\"https://polygonscan.com/tx/{transaction_hash}\"\n",
        "\n",
        "        print(\"✅ Submit done\\n\")\n",
        "        print(f\"Transaction link: {transaction_link}\")\n",
        "\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Command failed (exit code {e.returncode}):\", file=sys.stderr)\n",
        "        print(e.stderr.strip(), file=sys.stderr)\n",
        "        sys.exit(e.returncode)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_submit_to_contract()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "eaIpH1MFWadb",
        "outputId": "c261232d-43a9-4786-d1d2-61bfb1e90507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Submit done\n",
            "\n",
            "Transaction link: https://polygonscan.com/tx/0xade1227d4e36fcac2b57775c82deca01b63842e3d8bcbceaae77599aab637a76\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "t_sfdTo9tbP-"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}