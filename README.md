# Photo Metadata AI

AWS Rekognition photo categorization tool for real estate images. Automatically analyzes and categorizes property photos into organized folders based on detected content.

## Features

- ğŸ” **AI-Powered Analysis**: Uses AWS Rekognition to detect objects and scenes in images
- ğŸ  **Real Estate Focused**: Pre-configured categories for kitchen, bedroom, bathroom, living room, etc.
- ğŸ“ **Automatic Organization**: Creates organized folder structure in S3
- ğŸ“Š **Detailed Results**: Saves categorization results as JSON with confidence scores
- ğŸš€ **Batch Processing**: Process single properties or all properties at once
- ğŸ“¤ **Local to S3 Upload**: Upload images from local folders to S3 before processing
- ğŸ¤– **Advanced AI Analysis**: Deep property analysis using OpenAI GPT-4 Vision and IPFS schemas

## Quick Start

### Install from GitHub (Recommended)

```bash
# Install directly from GitHub repository
pip install git+https://github.com/yourusername/photo-meta-data-ai.git

# Set AWS credentials
export AWS_ACCESS_KEY_ID='your-access-key'
export AWS_SECRET_ACCESS_KEY='your-secret-key'
export AWS_DEFAULT_REGION='us-east-1'
export S3_BUCKET_NAME='your-bucket-name'

# Run the categorizer
photo-categorizer
```

### Local Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/photo-meta-data-ai.git
cd photo-meta-data-ai

# Install with one command
./install.sh

# Or install manually
pip install -e .
```

### Manual Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Install the package
pip install -e .

# Run the categorizer
photo-categorizer
```

## Usage

### Set AWS Credentials

```bash
export AWS_ACCESS_KEY_ID='your-access-key'
export AWS_SECRET_ACCESS_KEY='your-secret-key'
export AWS_DEFAULT_REGION='us-east-1'
export S3_BUCKET_NAME='your-bucket-name'
```

### Prepare Your Data

1. **Create a `seed.csv` file** with parcel IDs and addresses:
```csv
parcel_id,Address,method,headers,url,multiValueQueryString,body,json,source_identifier,County
30434108090030050,"1605 S US HIGHWAY 1 3E,PALM BEACH GARDENS","GET",,"https://pbcpao.gov/Property/Details",{"parcelId":["30434108090030050"]},,,30434108090030050,palm beach
52434205310037080,"2558 GARDENS PKWY,JUPITER","GET",,"https://pbcpao.gov/Property/Details",{"parcelId":["52434205310037080"]},,,52434205310037080,palm beach
```

2. **Create a folder structure** with parcel IDs as folder names:
```
images/
â”œâ”€â”€ 30434108090030050/
â”‚   â”œâ”€â”€ kitchen1.jpg
â”‚   â”œâ”€â”€ bedroom1.jpg
â”‚   â”œâ”€â”€ bathroom1.jpg
â”‚   â””â”€â”€ living1.jpg
â”œâ”€â”€ 52434205310037080/
â”‚   â”œâ”€â”€ exterior1.jpg
â”‚   â”œâ”€â”€ garage1.jpg
â”‚   â””â”€â”€ pool1.jpg
```

### Run the Categorizer

```bash
# Process a specific property
photo-categorizer

# Or run the script directly
python src/rekognition.py
```

### Run the AI Analyzer

```bash
# Process all properties with AI analysis
ai-analyzer --all-properties

# Process a specific property
ai-analyzer --property-id 30434108090030050

# Advanced usage
ai-analyzer --all-properties --batch-size 10 --max-workers 5
```

### Run the Parcel Processor

```bash
# Process parcels using CSV data
parcel-processor
```

This tool reads from:
- `upload_results.csv` - Contains property CIDs and data CIDs
- `seed.csv` - Contains parcel IDs and addresses

See [PARCEL_PROCESSOR_USAGE.md](PARCEL_PROCESSOR_USAGE.md) for detailed usage.

### Run the Bucket Manager

```bash
# Create bucket if it doesn't exist
bucket-manager --create

# Show bucket information
bucket-manager --info

# List all available buckets
bucket-manager --list

# Create bucket with custom name and region
bucket-manager --create --bucket-name my-custom-bucket --region us-west-2
```

The bucket manager automatically configures:
- Versioning
- Encryption
- Private access
- Security policies

The tool will give you three options:
1. **Upload images from local folder to S3** - Only upload, don't categorize
2. **Process existing images in S3** - Only categorize, don't upload
3. **Upload and then process** - Upload images and then categorize them

## How It Works

1. **Upload (Optional)**: Uploads images from local `images/` folder to S3
2. **Authentication**: Connects to AWS S3 and Rekognition services
3. **Image Discovery**: Finds all images for the specified property in S3
4. **AI Analysis**: Uses AWS Rekognition to detect objects and scenes
5. **Categorization**: Maps detected labels to real estate categories
6. **Organization**: Copies images to categorized folders in S3
7. **Results**: Saves detailed categorization results as JSON

## Categories

The tool automatically categorizes images into these real estate categories:

- ğŸ³ **Kitchen**: Appliances, cabinets, countertops
- ğŸ›ï¸ **Bedroom**: Beds, furniture, sleeping areas
- ğŸš¿ **Bathroom**: Toilets, showers, sinks, mirrors
- ğŸ›‹ï¸ **Living Room**: Sofas, TVs, fireplaces
- ğŸ½ï¸ **Dining Room**: Dining tables, chairs
- ğŸ  **Exterior**: Building exteriors, architecture
- ğŸš— **Garage**: Cars, vehicles, parking
- ğŸ’¼ **Office**: Desks, computers, work areas
- ğŸ‘• **Laundry**: Washing machines, dryers
- ğŸªœ **Stairs**: Staircases, railings
- ğŸ‘” **Closet**: Wardrobes, clothing storage
- ğŸŠ **Pool**: Swimming pools, water features
- ğŸŒ¿ **Balcony**: Terraces, patios, decks
- ğŸ“¦ **Other**: Unmatched items

## S3 Structure

After processing, your S3 bucket will be organized like this:

```
your-bucket-name/
â”œâ”€â”€ property-123/
â”‚   â”œâ”€â”€ kitchen/
â”‚   â”‚   â”œâ”€â”€ kitchen1.jpg
â”‚   â”‚   â””â”€â”€ kitchen2.jpg
â”‚   â”œâ”€â”€ bedroom/
â”‚   â”‚   â”œâ”€â”€ bedroom1.jpg
â”‚   â”‚   â””â”€â”€ bedroom2.jpg
â”‚   â”œâ”€â”€ bathroom/
â”‚   â”‚   â””â”€â”€ bathroom1.jpg
â”‚   â””â”€â”€ categorization_results.json
â””â”€â”€ property-456/
    â”œâ”€â”€ living_room/
    â”‚   â””â”€â”€ living1.jpg
    â””â”€â”€ categorization_results.json
```

## Requirements

- Python 3.7+
- AWS Account with S3 and Rekognition access
- AWS credentials configured
- S3 bucket: Configurable via `S3_BUCKET_NAME` environment variable (default: `photo-metadata-ai`)
- OpenAI API key (for AI analyzer)

## Configuration

### Environment Variables

- `AWS_ACCESS_KEY_ID`: Your AWS access key
- `AWS_SECRET_ACCESS_KEY`: Your AWS secret key
- `AWS_DEFAULT_REGION`: AWS region (default: us-east-1)
- `S3_BUCKET_NAME`: Your S3 bucket name (default: photo-metadata-ai) - **Automatically created if it doesn't exist**
- `OPENAI_API_KEY`: Your OpenAI API key (for AI analyzer)

### Local Folder Structure

The tool expects images to be stored locally with parcel IDs as folder names:
```
images/
â”œâ”€â”€ 30434108090030050/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ 52434205310037080/
    â”œâ”€â”€ image1.jpg
    â””â”€â”€ ...
```

**Note**: All tools now read from `seed.csv` to determine which properties to process.

### S3 Bucket

The tool expects images to be stored in S3 with this structure:
```
your-bucket-name/
â”œâ”€â”€ property-id-1/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ property-id-2/
    â”œâ”€â”€ image1.jpg
    â””â”€â”€ ...
```

## License

MIT License

Perfect! Now the tool is completely automatic. Here's the updated Google Colab code:

```python
# Install the tool from GitHub
!pip install git+https://github.com/elephant-xyz/photo-meta-data-ai.git

# Set AWS credentials
import os
os.environ['AWS_ACCESS_KEY_ID'] = 'your-access-key-here'
os.environ['AWS_SECRET_ACCESS_KEY'] = 'your-secret-key-here'
os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'
os.environ['S3_BUCKET_NAME'] = 'your-bucket-name-here'

# Run the photo categorizer (completely automatic)
!photo-categorizer
```

**What it will do automatically:**

1. ğŸ“¤ **Upload**: All images from `images/` folder to S3
2. ğŸ” **Analyze**: Every image with AWS Rekognition  
3. ğŸ·ï¸ **Categorize**: All images into appropriate folders
4. ğŸ“Š **Save Results**: JSON reports for each property
5. ğŸ“Š **Summary**: Final report of all processed properties

**No user prompts!** The tool will:
- Automatically find all property folders in the images directory
- Upload everything to S3
- Process all properties without asking which ones
- Show progress for each property
- Give you a final summary

**Just run the code and it will process everything in your images folder automatically!**

Make sure your images are organized like this:
```
images/
â”œâ”€â”€ property-123/
â”‚   â”œâ”€â”€ kitchen1.jpg
â”‚   â”œâ”€â”€ bedroom1.jpg
â”‚   â””â”€â”€ bathroom1.jpg
â”œâ”€â”€ property-456/
â”‚   â”œâ”€â”€ exterior1.jpg
â”‚   â””â”€â”€ garage1.jpg
â””â”€â”€ property-789/
    â”œâ”€â”€ office1.jpg
    â””â”€â”€ dining1.jpg
```